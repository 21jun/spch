hydra:
  job:
    chdir: False

defaults:
  - model: whisper-large-v3-turbo
  - data: stop_original
  - train: base

model:
  # processor_name_or_path: facebook/wav2vec2-base-960h
  freeze_feature_encoder: false
  freeze_encoder: false
  
  # attention_dropout: 0.1
  # hidden_dropout: 0.1
  # vocab_size: 1000

data:
  name: stop_original

train:
  project_name: seq.whisper.stop.en
  do_train: true
  do_eval: true
  output_dir: ${hydra:run.dir}
  logging_steps: 2
  num_epochs: 500
  learning_rate: 3e-4
  warmup_steps: 0
  save_steps: 500
  eval_steps: 500
  save_total_limit: 1
  seed: 777
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 2
  evaluation_strategy: steps
  do_grad_norm_clip: true
  max_grad_norm: 1.0
  log_with: mlflow
  upload_checkpoint: false
  checkpoint_save_limit: 1
