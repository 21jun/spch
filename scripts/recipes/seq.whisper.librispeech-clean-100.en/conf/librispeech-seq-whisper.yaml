hydra:
  job:
    chdir: False

defaults:
  - model: whisper-tiny
  - data: librispeech_lower_case
  - train: base

model:
  # processor_name_or_path: facebook/wav2vec2-base-960h
  freeze_feature_encoder: false
  freeze_encoder: false
  # attention_dropout: 0.1
  # hidden_dropout: 0.1
  # vocab_size: 1000

data:
  name: librispeech_lower_case
  data_module: scripts/recipes/seq.whisper.librispeech-clean-100.en/prepare/seq_whisper_dataset.py

train:
  project_name: seq.whisper.librispeech-clean-100.en
  do_train: true
  do_eval: true
  output_dir: ${hydra:run.dir}
  logging_steps: 2
  num_epochs: 500
  learning_rate: 3e-4
  warmup_steps: 0
  save_steps: 500
  eval_steps: 500
  save_total_limit: 1
  seed: 777
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 2
  evaluation_strategy: steps
  do_grad_norm_clip: true
  max_grad_norm: 1.0
  log_with: mlflow
  upload_checkpoint: false
  checkpoint_save_limit: 1
